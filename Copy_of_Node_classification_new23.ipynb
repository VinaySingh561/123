{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VinaySingh561/123/blob/master/Copy_of_Node_classification_new23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "hFwLefIsTwZL",
        "outputId": "09371ef6-a2ef-4800-d664-6120216947a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.1+cu116.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.9/dist-packages (2.1.1+pt113cu116)\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.9/dist-packages (0.6.17+pt113cu116)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.9/dist-packages (2.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.0.12)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:90% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# !pip install deeprobust\n",
        "# !conda install pytorch torchvision torchaudio -c pytorch\n",
        "import torch\n",
        "# print(torch.__version__)\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-geometric\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
        "\n",
        "from networkx.generators.random_graphs import erdos_renyi_graph\n",
        "from networkx.generators.random_graphs import barabasi_albert_graph\n",
        "from networkx.generators.community import stochastic_block_model\n",
        "from networkx.generators.random_graphs import watts_strogatz_graph\n",
        "from networkx.generators.community import random_partition_graph\n",
        "\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "\n",
        "import random\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYuSfuanVdLy"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import networkx as nx\n",
        "from networkx.algorithms import community\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data_dir = \"./data\"\n",
        "os.makedirs(data_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "rn5YNSFOog43",
        "outputId": "a23cdafc-c1f3-48d9-ee82-1821e9bdb4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>.container { width:90% !important; }</style>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy\n",
        "import torch\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
        "\n",
        "\n",
        "\n",
        "from networkx.generators.random_graphs import erdos_renyi_graph\n",
        "from networkx.generators.random_graphs import barabasi_albert_graph\n",
        "from networkx.generators.community import stochastic_block_model\n",
        "from networkx.generators.random_graphs import watts_strogatz_graph\n",
        "from networkx.generators.community import random_partition_graph\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import FactorAnalysis\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tCWvnpupR37"
      },
      "outputs": [],
      "source": [
        "from random import sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKccKEapUqT4"
      },
      "outputs": [],
      "source": [
        "# from deeprobust.graph.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0NC0KhdT8JA"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import csgraph\n",
        "from scipy.sparse.linalg import inv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7J04AkDioGuX",
        "outputId": "32081bc2-7689-4899-cca7-0b1890f6125c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "aoeWH74RoGuY",
        "outputId": "ddfd42af-a467-4653-dc1c-2d2ec14748fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Cora'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset = os.path.join(os.getcwd(),'Cora')\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch6kq6OxM8Ur",
        "outputId": "a67b638e-4752-4ec5-bdff-c7d5d556ed48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_node_feature_label.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/new_data/texas/out1_graph_edges.txt\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_0.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_1.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_2.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_3.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_4.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_5.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_6.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_7.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_8.npz\n",
            "Downloading https://raw.githubusercontent.com/graphdml-uiuc-jlu/geom-gcn/master/splits/texas_split_0.6_0.2_9.npz\n",
            "Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[183, 1703], edge_index=[2, 325], y=[183], train_mask=[183, 10], val_mask=[183, 10], test_mask=[183, 10])\n",
            "Homophilic ratio : 0.10769230872392654\n",
            "Sparsity of original graph : 0.0195160031225605\n",
            "torch.Size([183, 1703]) torch.Size([183, 183])\n",
            "torch.Size([183, 1703]) torch.Size([183, 183])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Done!\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import WebKB\n",
        "from torch_geometric.utils import to_dense_adj,homophily\n",
        "\n",
        "\n",
        "dataset = WebKB(root='/Texas',name='Texas')\n",
        "print(dataset[0])\n",
        "\n",
        "edge_list = dataset[0].edge_index\n",
        "NO_OF_EDGES = edge_list.shape[1]\n",
        "labels = dataset[0].y\n",
        "\n",
        "print(\"Homophilic ratio : \" + str(homophily(edge_list,labels,method='edge')))\n",
        "\n",
        "\n",
        "adj = to_dense_adj(dataset[0].edge_index)\n",
        "adj = adj[0]\n",
        "\n",
        "labels = labels.numpy()\n",
        "\n",
        "X = dataset[0].x\n",
        "X = X.to_dense()\n",
        "N = X.shape[0]\n",
        "NO_OF_CLASSES = 5\n",
        "\n",
        "sparsity_original = 2*NO_OF_EDGES/(N*(N-1))\n",
        "print(\"Sparsity of original graph : \" + str(sparsity_original))\n",
        "\n",
        "\n",
        "print(X.shape, adj.shape)\n",
        "\n",
        "nn = int(1*N)\n",
        "X = X[:nn,:]\n",
        "adj = adj[:nn,:nn]\n",
        "labels = labels[:nn]\n",
        "print(X.shape,adj.shape)\n",
        "\n",
        "# plot_graph(dataset[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPYnNp6moGua"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STsLjDMMN2bk",
        "outputId": "05bec912-ded7-467a-cf7d-fce0b523e833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([183, 183])\n"
          ]
        }
      ],
      "source": [
        "def get_laplacian(adj):\n",
        "    b=torch.ones(adj.shape[0])\n",
        "    return torch.diag(adj@b)-adj\n",
        "\n",
        "theta = get_laplacian(adj)\n",
        "print(theta.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxPj9tu-YZjX",
        "outputId": "b1767b92-52a8-4024-b85b-92bdbc8058f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 183\n"
          ]
        }
      ],
      "source": [
        "# dataset_name = 'flickr' \n",
        "\n",
        "# data = Dataset(root='', name=dataset_name, setting='gcn',seed=10)\n",
        "\n",
        "# adj, features, labels = data.adj, data.features, data.labels\n",
        "# idx_train, idx_val, idx_test = data.idx_train, data.idx_val, data.idx_test\n",
        "\n",
        "# theta = csgraph.laplacian(adj).tocsr()\n",
        "features = X.numpy()\n",
        "NO_OF_NODES = X.shape[0]\n",
        "# NO_OF_CLASSES =  7\n",
        "\n",
        "\n",
        "print(NO_OF_CLASSES,NO_OF_NODES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiN9k3_MueR-"
      },
      "outputs": [],
      "source": [
        "def convertScipyToTensor(coo):\n",
        "  try:\n",
        "    coo = coo.tocoo()\n",
        "  except:\n",
        "    coo = coo\n",
        "  values = coo.data\n",
        "  indices = np.vstack((coo.row, coo.col))\n",
        "\n",
        "  i = torch.LongTensor(indices)\n",
        "  v = torch.FloatTensor(values)\n",
        "  shape = coo.shape\n",
        "\n",
        "  return torch.sparse.FloatTensor(i, v, torch.Size(shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xla8XecUULkS"
      },
      "outputs": [],
      "source": [
        "from scipy.sparse import random\n",
        "from scipy.sparse.linalg import norm\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "p = X.shape[0]\n",
        "k = int(p*0.5)\n",
        "n = X.shape[1]\n",
        "lambda_param = 100\n",
        "beta_param = 50\n",
        "alpha_param = 100\n",
        "gamma_param = 100\n",
        "lr = 1e-5\n",
        "thresh = 1e-10\n",
        "\n",
        "from scipy.sparse import random\n",
        "from scipy.stats import rv_continuous\n",
        "class CustomDistribution(rv_continuous):\n",
        "    def _rvs(self,  size=None, random_state=None):\n",
        "        return random_state.standard_normal(size)\n",
        "temp = CustomDistribution(seed=1)\n",
        "temp2 = temp()  # get a frozen version of the distribution\n",
        "X_tilde = random(k, n, density=0.25, random_state=1, data_rvs=temp2.rvs)\n",
        "C = random(p, k, density=0.25, random_state=1, data_rvs=temp2.rvs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "metadata": {
        "id": "F6EoFQwmEIni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N7eCPKgHEIqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "zni5bnJP9WF7"
      },
      "outputs": [],
      "source": [
        "def experiment(lambda_param,beta_param,alpha_param,gamma_param,C,X_tilde,theta,X):\n",
        "      p = X.shape[0]\n",
        "      k = int(p*0.5)\n",
        "      n = X.shape[1]\n",
        "      ones = csr_matrix(np.ones((k,k)))\n",
        "      ones = convertScipyToTensor(ones)\n",
        "      ones = ones.to_dense()\n",
        "      J = np.outer(np.ones(k), np.ones(k))/k\n",
        "      J = csr_matrix(J)\n",
        "      J = convertScipyToTensor(J)\n",
        "      J = J.to_dense()\n",
        "      zeros = csr_matrix(np.zeros((p,k)))\n",
        "      zeros = convertScipyToTensor(zeros)\n",
        "      zeros = zeros.to_dense()\n",
        "      X_tilde = convertScipyToTensor(X_tilde)\n",
        "      X_tilde = X_tilde.to_dense()\n",
        "      C = convertScipyToTensor(C)\n",
        "      C = C.to_dense()\n",
        "      eye = torch.eye(k)\n",
        "      try:\n",
        "        theta = convertScipyToTensor(theta)\n",
        "      except:\n",
        "        theta = theta\n",
        "      try:\n",
        "        X = convertScipyToTensor(X)\n",
        "        X = X.to_dense()\n",
        "      except:\n",
        "        X = X\n",
        "\n",
        "      # if(torch.cuda.is_available()):\n",
        "      #   # print(\"yes\")\n",
        "      #   X_tilde = X_tilde.cuda()\n",
        "      #   C = C.cuda()\n",
        "      #   theta = theta.cuda()\n",
        "      #   X = X.cuda()\n",
        "      #   J = J.cuda()\n",
        "      #   zeros = zeros.cuda()\n",
        "      #   ones = ones.cuda()\n",
        "      #   eye = eye.cuda()\n",
        "        X_tilde = X_tilde\n",
        "        C = C\n",
        "        theta = theta\n",
        "        X = X\n",
        "        J = J\n",
        "        zeros = zeros\n",
        "        ones = ones\n",
        "        eye = eye\n",
        "\n",
        "      def update(X_tilde,C,i):\n",
        "          global L\n",
        "          thetaC = theta@C\n",
        "          CT = torch.transpose(C,0,1)\n",
        "          X_tildeT = torch.transpose(X_tilde,0,1)\n",
        "          CX_tilde = C@X_tilde\n",
        "          t1 = CT@thetaC + J\n",
        "          term_bracket = torch.linalg.pinv(t1)\n",
        "          thetacX_tilde = thetaC@(X_tilde)\n",
        "          \n",
        "          L = 1/k\n",
        "\n",
        "          t1 = -2*gamma_param*(thetaC@term_bracket)\n",
        "          t2 = alpha_param*(CX_tilde-X)@(X_tildeT)\n",
        "          t3 = 2*thetacX_tilde@(X_tildeT)\n",
        "          t4 = lambda_param*(C@ones)\n",
        "          t5 = 2*beta_param*(thetaC@CT@thetaC)\n",
        "          t6 = (1/2)*(np.linalg.det(torch.linalg.pinv(C)@thetaC@torch.linalg.pinv(C)))^(-1/2)  \n",
        "          # t6 = (torch.linalg.pinv(CT)@torch.linalg.pinv(C)).trace()\n",
        "          # print(\"X_tilde\", X_tilde.shape)\n",
        "          # print(\"thetaC\", thetaC.shape)\n",
        "          # print(\"X_tildeT\", X_tildeT.shape)\n",
        "          # print(\"C\",C.shape)\n",
        "          # t6 = torch.exp((-1/2)*(torch.transpose((X_tildeT@torch.transpose(thetaC,0,1)),0,1)@X_tildeT))\n",
        "          T2 = (t1+t2+t3+t4+t5+t6)/L\n",
        "          Cnew = (C-T2).maximum(zeros)\n",
        "          t1 = CT@thetaC*(2/alpha_param)\n",
        "          t2 = CT@C\n",
        "          t1 = torch.linalg.pinv(t1+t2)\n",
        "          t1 = t1@CT\n",
        "          t1 = t1@X\n",
        "          X_tilde_new = t1\n",
        "          Cnew[Cnew<thresh] = thresh\n",
        "          for i in range(len(Cnew)):\n",
        "              Cnew[i] = Cnew[i]/torch.linalg.norm(Cnew[i],1)\n",
        "          for i in range(len(X_tilde_new)):\n",
        "            X_tilde_new[i] = X_tilde_new[i]/torch.linalg.norm(X_tilde_new[i],1)\n",
        "          return X_tilde_new,Cnew\n",
        "\n",
        "\n",
        "      for i in tqdm(range(20)):\n",
        "          X_tilde,C = update(X_tilde,C,i)\n",
        "    \n",
        "      return X_tilde,C\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtUTjCIMxzoE"
      },
      "outputs": [],
      "source": [
        "def experiment2(lambda_param,beta_param,alpha_param,gamma_param,C,X_tilde,theta,X):\n",
        "      p = X.shape[0]\n",
        "      k = int(p*0.1)\n",
        "      n = X.shape[1]\n",
        "      ones = csr_matrix(np.ones((k,k)))\n",
        "      ones = convertScipyToTensor(ones)\n",
        "      ones = ones.to_dense()\n",
        "      J = np.outer(np.ones(k), np.ones(k))/k\n",
        "      J = csr_matrix(J)\n",
        "      J = convertScipyToTensor(J)\n",
        "      J = J.to_dense()\n",
        "      zeros = csr_matrix(np.zeros((p,k)))\n",
        "      zeros = convertScipyToTensor(zeros)\n",
        "      zeros = zeros.to_dense()\n",
        "      X_tilde = convertScipyToTensor(X_tilde)\n",
        "      X_tilde = X_tilde.to_dense()\n",
        "      C = convertScipyToTensor(C)\n",
        "      C = C.to_dense()\n",
        "      eye = torch.eye(k)\n",
        "      try:\n",
        "        theta = convertScipyToTensor(theta)\n",
        "      except:\n",
        "        theta = theta\n",
        "      try:\n",
        "        X = convertScipyToTensor(X)\n",
        "        X = X.to_dense()\n",
        "      except:\n",
        "        X = X\n",
        "\n",
        "      if(torch.cuda.is_available()):\n",
        "        # print(\"yes\")\n",
        "        X_tilde = X_tilde.cuda()\n",
        "        C = C.cuda()\n",
        "        theta = theta.cuda()\n",
        "        X = X.cuda()\n",
        "        J = J.cuda()\n",
        "        zeros = zeros.cuda()\n",
        "        ones = ones.cuda()\n",
        "        eye = eye.cuda()\n",
        "\n",
        "      def update(X_tilde,C,i):\n",
        "          global L\n",
        "          thetaC = theta@C\n",
        "          CT = torch.transpose(C,0,1)\n",
        "          X_tildeT = torch.transpose(X_tilde,0,1)\n",
        "          CX_tilde = C@X_tilde\n",
        "          t1 = CT@thetaC + J\n",
        "          term_bracket = torch.linalg.pinv(t1)\n",
        "          thetacX_tilde = thetaC@(X_tilde)\n",
        "          CTX = CT@X\n",
        "          \n",
        "          L = 1/k\n",
        "\n",
        "          t1 = -2*gamma_param*(thetaC@term_bracket)\n",
        "          t2 = alpha_param*X@((X_tilde - CTX).T)\n",
        "          # t3 = 2*thetacX_tilde@(X_tildeT)\n",
        "          t3 = zeros\n",
        "          t4 = lambda_param*(C@ones)\n",
        "          t5 = 2*beta_param*(thetaC@CT@thetaC)\n",
        "          T2 = (t1+t2+t3+t4+t5)/L\n",
        "          Cnew = (C-T2).maximum(zeros)\n",
        "          t1 = CT@thetaC*(2/alpha_param)\n",
        "          t2 = CT@C\n",
        "          t1 = torch.linalg.pinv(t1+t2)\n",
        "          t1 = t1@CT\n",
        "          t1 = t1@X\n",
        "          X_tilde_new = CTX\n",
        "          Cnew[Cnew<thresh] = thresh\n",
        "          for i in range(len(Cnew)):\n",
        "              Cnew[i] = Cnew[i]/torch.linalg.norm(Cnew[i],1)\n",
        "          for i in range(len(X_tilde_new)):\n",
        "            X_tilde_new[i] = X_tilde_new[i]/torch.linalg.norm(X_tilde_new[i],1)\n",
        "          return X_tilde_new,Cnew\n",
        "\n",
        "\n",
        "      for i in tqdm(range(25)):\n",
        "          X_tilde,C = update(X_tilde,C,i)\n",
        "    \n",
        "      return X_tilde,C\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haiUWegMoGuh"
      },
      "outputs": [],
      "source": [
        "def experiment3(lambda_param,beta_param,alpha_param,gamma_param,C,X_tilde,theta,X):\n",
        "      p = X.shape[0]\n",
        "      k = int(p*0.1)\n",
        "      n = X.shape[1]\n",
        "      ones = csr_matrix(np.ones((k,k)))\n",
        "      ones = convertScipyToTensor(ones)\n",
        "      ones = ones.to_dense()\n",
        "      J = np.outer(np.ones(k), np.ones(k))/k\n",
        "      J = csr_matrix(J)\n",
        "      J = convertScipyToTensor(J)\n",
        "      J = J.to_dense()\n",
        "      zeros = csr_matrix(np.zeros((p,k)))\n",
        "      zeros = convertScipyToTensor(zeros)\n",
        "      zeros = zeros.to_dense()\n",
        "      X_tilde = convertScipyToTensor(X_tilde)\n",
        "      X_tilde = X_tilde.to_dense()\n",
        "      C = convertScipyToTensor(C)\n",
        "      C = C.to_dense()\n",
        "      eye = torch.eye(k)\n",
        "      try:\n",
        "        theta = convertScipyToTensor(theta)\n",
        "      except:\n",
        "        theta = theta\n",
        "      try:\n",
        "        X = convertScipyToTensor(X)\n",
        "        X = X.to_dense()\n",
        "      except:\n",
        "        X = X\n",
        "\n",
        "      # if(torch.cuda.is_available()):\n",
        "      #   # print(\"yes\")\n",
        "      #   X_tilde = X_tilde.cuda()\n",
        "      #   C = C.cuda()\n",
        "      #   theta = theta.cuda()\n",
        "      #   X = X.cuda()\n",
        "      #   J = J.cuda()\n",
        "      #   zeros = zeros.cuda()\n",
        "      #   ones = ones.cuda()\n",
        "      #   eye = eye.cuda()\n",
        "      X_tilde = X_tilde\n",
        "      C = C\n",
        "      theta = theta\n",
        "      X = X\n",
        "      J = J\n",
        "      zeros = zeros\n",
        "      ones = ones\n",
        "      eye = eye\n",
        "\n",
        "      def update(X_tilde,C,i):\n",
        "          global L,adj\n",
        "          thetaC = theta@C\n",
        "          CT = torch.transpose(C,0,1)\n",
        "          X_tildeT = torch.transpose(X_tilde,0,1)\n",
        "          CX_tilde = C@X_tilde\n",
        "          t1 = CT@thetaC + J\n",
        "          term_bracket = torch.linalg.pinv(t1)\n",
        "          thetacX_tilde = thetaC@(X_tilde)\n",
        "          \n",
        "          L = 1/k\n",
        "\n",
        "          t1 = -2*gamma_param*(thetaC@term_bracket)\n",
        "          t2 = alpha_param*(CX_tilde-X)@(X_tildeT)\n",
        "          t3 = 2*thetacX_tilde@(X_tildeT)\n",
        "          t4 = lambda_param*(C@ones)\n",
        "          t5 = 2*beta_param*(adj@C)\n",
        "          \n",
        "          T2 = (t1+t2+t3+t4+t5)/L\n",
        "          Cnew = (C-T2).maximum(zeros)\n",
        "          t1 = CT@thetaC*(2/alpha_param)\n",
        "          t2 = CT@C\n",
        "          t1 = torch.linalg.pinv(t1+t2)\n",
        "          t1 = t1@CT\n",
        "          t1 = t1@X\n",
        "          X_tilde_new = t1\n",
        "          Cnew[Cnew<thresh] = thresh\n",
        "          for i in range(len(Cnew)):\n",
        "              Cnew[i] = Cnew[i]/torch.linalg.norm(Cnew[i],1)\n",
        "          for i in range(len(X_tilde_new)):\n",
        "            X_tilde_new[i] = X_tilde_new[i]/torch.linalg.norm(X_tilde_new[i],1)\n",
        "          return X_tilde_new,Cnew\n",
        "\n",
        "\n",
        "      for i in tqdm(range(15)):\n",
        "          X_tilde,C = update(X_tilde,C,i)\n",
        "    \n",
        "      return X_tilde,C\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnKqrqAS9qmw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = GCNConv(X.shape[1], 64)\n",
        "        self.conv2 = GCNConv(64, NO_OF_CLASSES)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        self.conv2.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "\n",
        "        #print(\"Checking 1: x\", x.shape, \"Edge index:\", edge_index.shape)\n",
        "        x = self.conv1(x, edge_index)\n",
        "        #print(\"Checking 2: convolution done, new x:\", x.shape)\n",
        "        x = F.relu(x)\n",
        "        #print(\"Checking 3: x\", x.shape, \"training:\", self.training)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        #print(\"Checking 4: dropout done new x\", x.shape, \"Edge index:\", edge_index.shape)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        #print(\"Checking 5: x\", x.shape)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StlALggCABGw"
      },
      "outputs": [],
      "source": [
        "from random import sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78DErAOL9vVT"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch_geometric.utils import dense_to_sparse,homophily\n",
        "\n",
        "def get_accuracy(C_0,L,X_t_0):\n",
        "    global labels, NO_OF_CLASSES,k\n",
        "    t=[]\n",
        "    for i in [1,2,3,4,5,6,7,8,9,10]: \n",
        "        C_0_new=np.zeros(C_0.shape)\n",
        "        for i in range(C_0.shape[0]):\n",
        "            C_0_new[i][np.argmax(C_0[i])]=1\n",
        "        # print(C_0_new)\n",
        "        # C_0_new=C_0\n",
        "        from scipy import sparse\n",
        "        #Lc=C_0.T@L@C_0\n",
        "        Lc=C_0_new.T@L@C_0_new\n",
        "        # print(\"L:\", Lc.shape)\n",
        "        # Lc=L_new\n",
        "        #print(Lc)\n",
        "        Wc=(-1*Lc)*(1-np.eye(Lc.shape[0]))\n",
        "        # print(\"W:\", Wc.shape)\n",
        "        Wc[Wc<0.1]=0\n",
        "        Wc=sparse.csr_matrix(Wc)\n",
        "        Wc = Wc.tocoo()\n",
        "        row = torch.from_numpy(Wc.row).to(torch.long)\n",
        "        col = torch.from_numpy(Wc.col).to(torch.long)\n",
        "        edge_index_coarsen2 = torch.stack([row, col], dim=0)\n",
        "        #print(\"edgecoarsen:\", edge_index_coarsen2.shape)\n",
        "        edge_weight = torch.from_numpy(Wc.data)\n",
        "        #print(\"edgeweight:\", edge_weight.shape)\n",
        "        def one_hot(x, class_count):\n",
        "            return torch.eye(class_count)[x, :]\n",
        "\n",
        "        device = torch.device('cpu')\n",
        "        labels=labels\n",
        "        Y = labels\n",
        "        #print(\"Y:\", Y.shape)\n",
        "        Y = one_hot(Y,NO_OF_CLASSES)\n",
        "        # NO_OF_CLASSES=Y.shape[1]\n",
        "        P=np.linalg.pinv(C_0_new)\n",
        "        labels_coarse = torch.argmax(torch.sparse.mm(torch.Tensor(P).double() , Y.double()).double() , 1)\n",
        "        #print(\"Lables:\", labels_coarse.shape)\n",
        "\n",
        "        #torch.Tensor(C2)@X\n",
        "        # Wc[Wc<0.01]=0\n",
        "        Wc=Wc.toarray()\n",
        "        adjtemp = torch.tensor(Wc)\n",
        "        edge_list_temp = dense_to_sparse(adjtemp)[0]\n",
        "        # print(edge_list_temp)\n",
        "        # print(labels_coarse)\n",
        "        print(\"Homophilic ratio : \" + str(homophily(edge_list_temp,labels_coarse,method='edge')))\n",
        "        number_of_edges = edge_list_temp.shape[1]\n",
        "        n = labels_coarse.shape[0]\n",
        "        sparsity = 2*number_of_edges/(n*(n-1))\n",
        "        print(\"Sparsity : \" + str(sparsity))\n",
        "    \n",
        "        #\n",
        "        C2=np.linalg.pinv(C_0_new)\n",
        "        model=Net().to(device)\n",
        "        device = torch.device('cpu')\n",
        "        lr=0.01\n",
        "        decay=0.0001\n",
        "        try:\n",
        "          X=np.array(features.todense())\n",
        "        except:\n",
        "          X = np.array(features)\n",
        "        #print(\"X:\",X.shape)\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=decay)\n",
        "        # criterion=torch.nn.CrossEntropyLoss()\n",
        "        x=sample(range(0, int(k)), k)\n",
        "      \n",
        "        from datetime import datetime\n",
        "        Xt=P@X\n",
        "        # Xt=X_t_0\n",
        "        def train():\n",
        "            model.train()\n",
        "            optimizer.zero_grad()\n",
        "            out = model(torch.Tensor(Xt).to(device),edge_index_coarsen2)\n",
        "            loss = F.nll_loss(out[x], labels_coarse[x])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            return loss\n",
        "        now1 = datetime.now()\n",
        "        losses=[]\n",
        "        for epoch in range(10):\n",
        "            loss=train()\n",
        "            losses.append(loss)\n",
        "            if(epoch%100==0):\n",
        "                print(f'Epoch: {epoch:03d},loss: {loss:.4f}')\n",
        "        now2 = datetime.now()        \n",
        "        pred=model(torch.Tensor(Xt).to(device),edge_index_coarsen2).argmax(dim=1)        \n",
        "        def train_accuracy():\n",
        "            model.eval()\n",
        "            correct = (pred[x] == labels_coarse[x]).sum()\n",
        "            acc = int(correct) /len(x)\n",
        "            return acc\n",
        "    \n",
        "        t+=[(now2-now1).total_seconds()]\n",
        "\n",
        "        zz=sample(range(0, int(NO_OF_NODES)), NO_OF_NODES)\n",
        "        Wc=sparse.csr_matrix(adj)\n",
        "        Wc = Wc.tocoo()\n",
        "        row = torch.from_numpy(Wc.row).to(torch.long)\n",
        "        col = torch.from_numpy(Wc.col).to(torch.long)\n",
        "        edge_index_coarsen = torch.stack([row, col], dim=0)\n",
        "        edge_weight = torch.from_numpy(Wc.data)\n",
        "        pred=model(torch.Tensor(X),edge_index_coarsen).argmax(dim=1)\n",
        "        pred=np.array(pred)\n",
        "        correct =(pred[zz]==labels[zz]).sum()\n",
        "        acc = int(correct) /NO_OF_NODES\n",
        "        return acc\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4ABGaC4oGul"
      },
      "outputs": [],
      "source": [
        "from torch_geometric.utils import dense_to_sparse,homophily\n",
        "\n",
        "def getSparsityAndHomophily(C,theta):\n",
        "    theta = C.T@theta@C\n",
        "    adjtemp = -theta\n",
        "    for i in range(adjtemp.shape[0]):\n",
        "      adjtemp[i,i]=0\n",
        "    adjtemp[adjtemp<0.01]=0\n",
        "    temp = dense_to_sparse(adjtemp)\n",
        "    edge_list_temp = temp[0]\n",
        "    # ytemp = temp[1]\n",
        "    # P = torch.linalg.pinv(C)\n",
        "    # labels = \n",
        "    # # print(edge_list)\n",
        "    number_of_edges = edge_list_temp.shape[1]\n",
        "    # n = adjtemp.shape[0]\n",
        "\n",
        "    # print(\"Homophilic ratio : \" + str(homophily(edge_list_temp,ytemp,method='node')))\n",
        "    sparsity = 2*number_of_edges/(n*(n-1))\n",
        "    print(\"Sparsity : \" + str(sparsity))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "ejPLG3L9zYrc",
        "outputId": "728b7882-4fa0-4b41-c11b-b80622c86d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/20 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LinAlgError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-cc4724558f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m           \u001b[0;31m# try:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m           \u001b[0mX_t_0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma_param\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m           \u001b[0mL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-d8e31b96ea0e>\u001b[0m in \u001b[0;36mexperiment\u001b[0;34m(lambda_param, beta_param, alpha_param, gamma_param, C, X_tilde, theta, X)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m           \u001b[0mX_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mX_tilde\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-d8e31b96ea0e>\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(X_tilde, C, i)\u001b[0m\n\u001b[1;32m     64\u001b[0m           \u001b[0mt4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_param\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m           \u001b[0mt5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbeta_param\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthetaC\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mCT\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mthetaC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m           \u001b[0mt6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mthetaC\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpinv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m^\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m           \u001b[0;31m# t6 = (torch.linalg.pinv(CT)@torch.linalg.pinv(C)).trace()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m           \u001b[0;31m# print(\"X_tilde\", X_tilde.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdet\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mdet\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m     \u001b[0m_assert_stacked_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2143\u001b[0;31m     \u001b[0m_assert_stacked_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2144\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->D'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->d'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_assert_stacked_square\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Last 2 dimensions of the array must be square'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_assert_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pylab as plt\n",
        "from torch_geometric.utils import dense_to_sparse,homophily\n",
        "        # sns.heatmap(C_0.T@C_0)\n",
        "        \n",
        "\n",
        "#0.0001,0.0001,10,0.0001\n",
        "for lambda_param in [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]:\n",
        "  for beta_param in [0.0001, 0.001, 0.01, 0.1, 1, 10,100]:\n",
        "    for alpha_param in [0.0001, 0.001, 0.01, 0.1, 1,10,100]:\n",
        "      for gamma_param in [0.0001, 0.001, 0.01, 0.1, 1,10,100]:\n",
        "\n",
        "        av = []\n",
        "\n",
        "        for _ in range(3):\n",
        "\n",
        "          X_tilde = random(k, n, density=0.15, random_state=1, data_rvs=temp2.rvs)\n",
        "          C = random(p, k, density=0.15, random_state=1, data_rvs=temp2.rvs)\n",
        "\n",
        "          # try:\n",
        "\n",
        "          X_t_0,C_0 = experiment(lambda_param,beta_param,alpha_param,gamma_param,C,X_tilde,theta,X)\n",
        "          L = theta\n",
        "          \n",
        "          # Ltemp = (C_0.T)@theta@C_0\n",
        "          # adjtemp = -Ltemp\n",
        "          # for i in range(adjtemp.shape[0]):\n",
        "          #   adjtemp[i,i]=0\n",
        "          # temp = dense_to_sparse(adjtemp)\n",
        "          # edge_list_temp = temp[0]\n",
        "          # ytemp = temp[1]\n",
        "          # # print(edge_list)\n",
        "          # number_of_edges = edge_list_temp.shape[0]\n",
        "          # n = adjtemp.shape[0]\n",
        "\n",
        "          # print(\"Homophilic ratio : \" + str(homophily(edge_list_temp,ytemp)))\n",
        "          # sparsity = 2*number_of_edges/(n*(n-1))\n",
        "         \n",
        "\n",
        "\n",
        "\n",
        "          getSparsityAndHomophily(C_0,theta)\n",
        "\n",
        "          C_0 = C_0.cpu().detach().numpy()\n",
        "          X_t_0 = X_t_0.cpu().detach().numpy()\n",
        "          C_t_0 = C_0.T\n",
        "          \n",
        "          try:\n",
        "            L = L.cpu().detach().numpy()\n",
        "          except:\n",
        "            L = L\n",
        "          \n",
        "          acc = get_accuracy(C_0,L,X_t_0)\n",
        "          av.append(acc)\n",
        "          # if(acc < 0.80):\n",
        "          #   break\n",
        "          print(\"Accuracy = \" + str(acc) + \" \" + str(lambda_param)+\" \" + str(beta_param)+\" \"+str(alpha_param)+\" \"+str(gamma_param))\n",
        "\n",
        "          # except:\n",
        "\n",
        "          #     print(\"SVD DID NOT CONVERGE\")\n",
        "\n",
        "        print(\"Average accuracy = \" + str(np.mean(av)*100)  + \" +/- \" + str(np.std(av)*100)) \n",
        "     \n",
        "\n",
        "    # X_t_0 = X_tilde\n",
        "    # X = X.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Exploration"
      ],
      "metadata": {
        "id": "xA2fvVvJrhCx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5lc4VbnoGun"
      },
      "outputs": [],
      "source": [
        "type(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print some dataset statistics\n",
        "print('Number of graphs:', len(dataset))\n",
        "print('Number of features:', dataset.num_features)\n",
        "print('Number of classes:', dataset.num_classes)\n",
        "\n",
        "# Visualize one of the graphs using NetworkX\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from(range(dataset[0].num_nodes))\n",
        "G.add_edges_from(dataset[0].edge_index.t().tolist())\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "nx.draw(G, node_size=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iFs5L7qaqeMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the feature matrix of the first graph in the dataset\n",
        "first_graph_features = dataset[0].x\n",
        "\n",
        "print(first_graph_features.shape)\n"
      ],
      "metadata": {
        "id": "THn6PgnwrB1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(first_graph_features[:,:])"
      ],
      "metadata": {
        "id": "-OZVUdESsPcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count(x):\n",
        "  count  = 0\n",
        "  for i in range(len(x)):\n",
        "    if x[i]==1:\n",
        "      count += 1\n",
        "  return count   "
      ],
      "metadata": {
        "id": "vC6ZL1p4sYvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 183 Nodes"
      ],
      "metadata": {
        "id": "C9wW1cM3209J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "dict = {}\n",
        "for i in range(len(first_graph_features[:,0])):\n",
        "  dict[str(i)] = count(first_graph_features[i,:])"
      ],
      "metadata": {
        "id": "o7N5lW58sors"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "feature_data = pd.DataFrame(dict, index = [\"Vinay\"])"
      ],
      "metadata": {
        "id": "r23aZEt8s18w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(feature_data.iloc[0]/feature_data.iloc[0].sum()).plot()"
      ],
      "metadata": {
        "id": "pXTOCPOst0SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilty_data_feature = feature_data.iloc[0]/feature_data.iloc[0].sum()"
      ],
      "metadata": {
        "id": "w27WoGsryPNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilty_data_feature"
      ],
      "metadata": {
        "id": "jKUVu4dtzu-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_data.head()"
      ],
      "metadata": {
        "id": "4TICB_lx2OGN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1703 features at every node"
      ],
      "metadata": {
        "id": "7BwmSuEv3Ami"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_1 = {}\n",
        "for i in range(len(first_graph_features[0,:])):\n",
        "  dict_1[str(i)] = count(first_graph_features[:,i])\n",
        "\n",
        "import pandas as pd\n",
        "feature_dataset = pd.DataFrame(dict_1, index = [\"Vinay_features\"])  \n",
        "feature_dataset.head()"
      ],
      "metadata": {
        "id": "cHLk1-Xd2rmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilty_dataset_feature = feature_dataset.iloc[0]/feature_dataset.iloc[0].sum()"
      ],
      "metadata": {
        "id": "ThIaFmQh8cgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilty_dataset_feature"
      ],
      "metadata": {
        "id": "iIr0yRZPrccN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilty_dataset_feature.values.shape"
      ],
      "metadata": {
        "id": "vYFKtw7Rr5E8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P = np.dot(probabilty_data_feature.values.reshape(-1,1),probabilty_dataset_feature.values.reshape(-1,1).T)"
      ],
      "metadata": {
        "id": "i12_czgusTR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P.shape"
      ],
      "metadata": {
        "id": "lLr7luFxthOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(P[150])"
      ],
      "metadata": {
        "id": "dzRvs6-HukDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Total Probability\n",
        "P[:].sum()"
      ],
      "metadata": {
        "id": "qfXrT6CSvZBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P.shape[0]"
      ],
      "metadata": {
        "id": "pJFW7NjYx6v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# compute the base-2 logarithm of 8\n",
        "x = 8\n",
        "log2_x = math.log2(x)\n",
        "print(\"Base-2 logarithm of\", x, \"is\", log2_x)\n"
      ],
      "metadata": {
        "id": "2jqsTx_fzNAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# Von Neuman Entropy \n",
        "entropy = 0;\n",
        "for i  in range(P.shape[0]):\n",
        "  for j in range(P.shape[1]):\n",
        "    if(P[i][j] != 0):\n",
        "      entropy  = entropy + P[i][j]*math.log2(P[i][j])"
      ],
      "metadata": {
        "id": "9S4qt7A_v5OC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entropy"
      ],
      "metadata": {
        "id": "5f9Mnmwt0U8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Cora Dataset:***"
      ],
      "metadata": {
        "id": "Y5MuVQdAxbrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# print(torch.__version__)\n",
        "!pip install torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
        "!pip install torch-geometric\n",
        "import os\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch_geometric\n",
        "from torch_geometric.utils import to_networkx\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import networkx as nx\n",
        "from networkx.algorithms import community\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "data_dir = \"./data\"\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "qxz29J3dxaqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load data\n",
        "dataset = Planetoid(root=data_dir, name='Cora')\n",
        "print(dataset)\n",
        "data = dataset[0]\n",
        "print(data)"
      ],
      "metadata": {
        "id": "ePkHkTm50zbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of nodes: {data.num_nodes}')\n",
        "print(f'Number of edges: {data.num_edges}')\n",
        "print(f'Has isolated nodes: {data.has_isolated_nodes()}')  # False\n",
        "print(f'Has self-loops: {data.has_self_loops()}')  # False\n",
        "print(f'Is undirected: {data.is_undirected()}')  # True                                                                                                                                                                               "
      ],
      "metadata": {
        "id": "MJ405uAZ0jIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the feature matrix of the first graph in the dataset\n",
        "first_graph_features = dataset[0].x\n",
        "import numpy\n",
        "import sys\n",
        "\n",
        "\n",
        "numpy.set_printoptions(threshold=sys.maxsize)\n",
        "print(first_graph_features)"
      ],
      "metadata": {
        "id": "vfDghqMlyl5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(first_graph_features[:,:])"
      ],
      "metadata": {
        "id": "TvJO_-5yyq0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#finding the edges held by 30th node\n",
        "edge_index = data.edge_index.numpy()\n",
        "print(edge_index.shape)\n",
        "edge_example = edge_index[:, np.where(edge_index[0]==30)[0]]\n",
        "edge_example"
      ],
      "metadata": {
        "id": "Vs7yRpKG11P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#network centered on this node\n",
        "node_example = np.unique(edge_example.flatten())\n",
        "plt.figure(figsize=(10, 6))\n",
        "G = nx.Graph()\n",
        "G.add_nodes_from(node_example)\n",
        "G.add_edges_from(list(zip(edge_example[0], edge_example[1])))\n",
        "nx.draw_networkx(G, with_labels=False)\n"
      ],
      "metadata": {
        "id": "-TX19kNE18NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')"
      ],
      "metadata": {
        "id": "tZbCUjhg8bHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = to_networkx(data, to_undirected=True)\n",
        "degrees = [val for (node, val) in G.degree()]\n",
        "display(pd.DataFrame(pd.Series(degrees).describe()).transpose().round(2))\n",
        "print(len(degrees))\n",
        "print(sum(degrees))\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(degrees, bins=50)\n",
        "plt.xlabel(\"node degree\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m8EYCMgX8idS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph to see where the top 10 nodes with highest degree are located"
      ],
      "metadata": {
        "id": "pPaXL2TP9sVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = to_networkx(data, to_undirected=True)\n",
        "pos = nx.spring_layout(G, seed=42)\n",
        "cent = nx.degree_centrality(G)\n",
        "node_size = list(map(lambda x: x * 500, cent.values()))\n",
        "cent_array = np.array(list(cent.values()))\n",
        "threshold = sorted(cent_array, reverse=True)[10]\n",
        "print(\"threshold\", threshold)\n",
        "cent_bin = np.where(cent_array >= threshold, 1, 0.1)\n",
        "plt.figure(figsize=(12, 12))\n",
        "nodes = nx.draw_networkx_nodes(G, pos, node_size=node_size,\n",
        "                               cmap=plt.cm.plasma,\n",
        "                               node_color=cent_bin,\n",
        "                               nodelist=list(cent.keys()),\n",
        "                               alpha=cent_bin)\n",
        "edges = nx.draw_networkx_edges(G, pos, width=0.25, alpha=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nMBv5UxK9qR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of features: {data.num_node_features}')"
      ],
      "metadata": {
        "id": "Pbo6p_FS-AMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(data.x[0]))\n",
        "data.x[0][:20]"
      ],
      "metadata": {
        "id": "wiTfSiz5-nxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of edge features: {data.num_edge_features}')"
      ],
      "metadata": {
        "id": "mAmkG-hvANN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of classes: {dataset.num_classes}')"
      ],
      "metadata": {
        "id": "qbulyOkHAgqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict = {\n",
        "    0: \"Theory\",\n",
        "    1: \"Reinforcement_Learning\",\n",
        "    2: \"Genetic_Algorithms\",\n",
        "    3: \"Neural_Networks\",\n",
        "    4: \"Probabilistic_Methods\",\n",
        "    5: \"Case_Based\",\n",
        "    6: \"Rule_Learning\"}\n",
        "data.y[:10]"
      ],
      "metadata": {
        "id": "jL00sVzpAjdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counter = collections.Counter(data.y.numpy())\n",
        "counter = dict(counter)\n",
        "print(counter)\n",
        "count = [x[1] for x in sorted(counter.items())]\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(7), count)\n",
        "plt.xlabel(\"class\", size=20)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9EoWs1nFAv8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = to_networkx(data, to_undirected=True)\n",
        "node_color = []\n",
        "nodelist = [[], [], [], [], [], [], []]\n",
        "colorlist = ['#e41a1c', '#377eb8', '#4daf4a', '#984ea3', '#ff7f00', '#ffff33', '#a65628']\n",
        "labels = data.y\n",
        "for n, i in enumerate(labels):\n",
        "    node_color.append(colorlist[i])\n",
        "    nodelist[i].append(n)\n",
        "pos = nx.spring_layout(G, seed = 42)\n",
        "plt.figure(figsize = (10, 10))\n",
        "labellist = list(label_dict.values())\n",
        "for num, i in enumerate(zip(nodelist, labellist)):\n",
        "    n, l = i[0], i[1]\n",
        "    nx.draw_networkx_nodes(G, pos, nodelist=n, node_size = 5, node_color = colorlist[num], label=l)\n",
        "nx.draw_networkx_edges(G, pos, width = 0.25)\n",
        "plt.legend(bbox_to_anchor=(1, 1), loc='upper left')"
      ],
      "metadata": {
        "id": "rCuIG__4A7cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = data.y.numpy()\n",
        "connected_labels_set = list(map(lambda x: labels[x], data.edge_index.numpy()))\n",
        "connected_labels_set = np.array(connected_labels_set)\n",
        "def add_missing_keys(counter, classes):\n",
        "    for x in classes:\n",
        "        if x not in counter.keys():\n",
        "            counter[x] = 0\n",
        "    return counter\n",
        "label_connection_counts = []\n",
        "for i in range(7):\n",
        "    print(f\"label: {i}\")\n",
        "    connected_labels = connected_labels_set[:, np.where(connected_labels_set[0] == i)[0]]\n",
        "    print(connected_labels.shape[1], \"edges\")\n",
        "    counter = collections.Counter(connected_labels[1])\n",
        "    counter = dict(counter)\n",
        "    print(counter)\n",
        "    counter = add_missing_keys(counter, range(7))\n",
        "    items = sorted(counter.items())\n",
        "    items = [x[1] for x in items]\n",
        "    label_connection_counts.append(items)\n",
        "label_connection_counts = np.array(label_connection_counts)\n",
        "plt.figure(figsize=(9, 7))\n",
        "plt.rcParams[\"font.size\"] = 13\n",
        "hm = sns.heatmap(label_connection_counts, annot=True, cmap='hot_r', cbar=True, square=True)\n",
        "plt.xlabel(\"class\",size=20)\n",
        "plt.ylabel(\"class\",size=20)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-S3s9yWuBXV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_connection_counts.diagonal().sum() / label_connection_counts.sum()"
      ],
      "metadata": {
        "id": "ijdI1RQMDyJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
        "print(f'Number of validation nodes: {data.val_mask.sum()}')\n",
        "print(f'Number of test nodes: {data.test_mask.sum()}')"
      ],
      "metadata": {
        "id": "xdmHNX2WEC5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_type_array = np.zeros(data.num_nodes)\n",
        "split_type_array[np.where(data.train_mask == True)[0]] = 1\n",
        "split_type_array[np.where(data.val_mask == True)[0]] = 2\n",
        "split_type_array[np.where(data.test_mask == True)[0]] = 3\n",
        "split_type_array\n",
        "plt.scatter(range(2708), split_type_array)\n",
        "plt.xlabel(\"index\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GopWoLI9EK2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titles = [\"Training\", \"Validation\", \"Test\"]\n",
        "fig, axes = plt.subplots(ncols=3, figsize=(21, 6))\n",
        "for i in range(3):\n",
        "    counter = collections.Counter(data.y.numpy()[np.where(split_type_array == i + 1)[0]])\n",
        "    counter = dict(counter)\n",
        "    print(titles[i], counter)\n",
        "count = [x[1] for x in sorted(counter.items())]\n",
        "# plt.figure(figsize=(10, 6))\n",
        "axes[i].bar(range(7), count)\n",
        "axes[i].set_xlabel(\"class\", size=20)\n",
        "axes[i].set_title(titles[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ocNtZ0TkElMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sympy import *\n",
        "import numpy as np\n",
        "x = Symbol('x')\n",
        "y = log(x**2) + 1\n",
        "yprime = y.diff(x)\n",
        "yprime\n"
      ],
      "metadata": {
        "id": "I1xPlSnKKsYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtilde.size()"
      ],
      "metadata": {
        "id": "1ZMxqitbzH4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KHBXOJ_G5rkX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "FGC",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "969efddd5922f42744441fca4a7e1e35c9b91771f089e8346c81a80fe202b860"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}